## Findog
* 2024 대전 공공데이터활용 창업경진대회
* 도메인 : 안면 인식 AI와 비문 인식 AI를 활용한 실종 반려견 찾기 APP
* 개발 기간 : 2024.06.28 ~ 2024.07.09

## 프로젝트 소개
![Findog](https://github.com/user-attachments/assets/b1e43288-9cd3-4f0c-906b-89a1450f8cbd)
<p>
  지난 10년간 반려동물 양육비율은 점점 증가하는 추세를 보이고 있습니다. 조사 결과 이에 따라<br>
  유실 및 유기동물 수의 추이 또한 매해 증가하는 것으로 확인되었습니다. 국내에서는 이런 반려동물의<br> 
  유실 방지를 위해 식별칩을 삽입하고 부착하여 신고하는 시스템을 의무 시행 중에 있지만 가족의 품에<br>
  돌아가는 유실 동물의 비율은 12%에 불과한 것이 현실입니다. 또한, 기존 방식으로는 반려견을 <br>
  잃어버렸을 때 유기돌물 공고를 확인하기 위해 여러 보호소의 홈페이지에 들어가 보호소 및 개인이 <br>
  올린 공고를 하나하나 확인해야 하는 것이 현 주소입니다.<br>

  이에 저희는 공공데이터를 활용하여 수많은 공고들을 한 군데에서 통합적으로 확인할 수 있는 플랫폼을<br> 
  만들고 실종된 반려견을 안면 인식 AI와 비문 인식 AI를 활용하여 비슷한 강아지를 쉽게 조회할 수 있도록 <br>
  함으로써 최대한 많은 유실 동물들의 자신들의 집으로 돌아갈 수 있도록 도움을 드릴 수 있습니다.<br>
</p>

## 주요 기능 소개
### (1) 실종 공고 등록
실종된 반려견의 사진, 이름, 나이, 품종, 성별, 털색, 중성화 여부와 같은 정보들을 입력합니다. 해당 사진을<br>
통해 Findog의 AI가 자동으로 사진의 비문을 인식합니다.

![1-ezgif com-video-to-gif-converter (1)](https://github.com/user-attachments/assets/6675b05d-d6f3-416c-b26a-1aabea7830f8)

### (2) AI를 이용한 반려견 찾기
AI로 검색하기 버튼을 이용하여 자신의 반려견과 유사한 반려견을 찾습니다.<br>
잃어버린 자신의 반려견을 선택하고 사용자가 원하는 자신의 반려견과의 유사도를 설정합니다.<br>
선택한 사진을 토대로 AI가 비문을 탐지합니다. 비문이 탐지되면 해당 비문을 토대로<br>
비문 인식 AI를 통해 유사한 강아지의 목록을 반환합니다.<br>
비문이 탐지 되지 않을 시, 안면 인식 AI를 통해 유사한 강아지의 목록을 반환합니다.

![7-ezgif com-video-to-gif-converter (1)](https://github.com/user-attachments/assets/9d6df361-b8f8-44b8-9b59-0f388a0b8b08)

![10-ezgif com-video-to-gif-converter (1)](https://github.com/user-attachments/assets/0bee42e3-4eea-40d4-9902-4907e8e10e7c)

### (3) 개인 보호 및 보호소 공고 확인
Findog에서 각 보호소의 데이터를 통합적으로 제공하기 때문에 기존처럼 다른 보호소의 공고를<br>
확인하기 위해 타 사이트를 접속할 필요 없이 원하는 지역, 보호소를 선택하면 해당 보호소 혹은<br>
개인의 공고를 확인할 수 있습니다.<br>
공고는 사용자의 의도에 맞춰 보호소별, 지역별, 최신순 등으로 정렬하여 조회할 수 있습니다.

### ** 여기 들어가야 하는 움짤 2개가 10MB가 넘어서 ISSUE에 넣고 나오는 형식으로 바꿔야 하는데 그게 안됩니다.**

## AI 소개
### 비문 탐지 AI
> crop dog nose(강아지 코 추출)<br>

객체 탐지(object-detection)은 한 이미지에서 객체와 그 경계 상자(bounding-box)를 탐지하는 기술이빈다.<br>
객체 탐지 알고리즘은 이미지를 입력으로 받고, 경계 상자와 객체 클라스 리스트를 출력하여 이때 경계 상자에<br>
대응하는 예측 클래스와 클래스의 신뢰도를 출력합니다. 저희는 YoloV5n와 YoloV8s 모델을 사용하였습니다.<br>

### 비문 인식 AI
> 전처리<br>

비문 인식 AI의 전처리를 이미지 증강 및 이미지 크기 변환을 진행합니다.
1. 이미지를 GrayScale을 통해 흑백처리합니다.
2. 96X96의 크기로 이미지 사이즈를 조정합니다. 이후 조정된 이미지의 픽셀들을 0~1의 값으로 정규화합니다.
3. imgAug 라이브러리를 이용하여 이미지 데이터를 증강합니다.<br>
   a. 해당 전처리 과정에서는 가우시안 블러, 확대, 축소, 회전, 이동, 순서 변경을 적용하였습니다.<br>
   b. 가우시안 블러란?<br>
    * 가우스 함수를 이용하여 합성곱을 통해 이미지의 노이즈를 줄이는 기법<br>
4. 이미지 증강 이후 이미지를 모델에 맞게 차원을 변환합니다.

> 인식<br>

사용자가 선택한 이미지와 비교할 이미지 리스트의 이미지들을 전처리합니다.<br>
비교할 이미지 리스트를 돌면서 샴네트워크 기반 모델을 이용하여 기본 이미지와 비교할 이미지의<br>
유사도 결과를 예측합니다. 예측한 결과가 사용자가 선택한 유사도보다 높다면<br>
비슷한 비문으로 판단합니다.<br>

> 샴 네트워크<br>

두 사진을 입력으로 받아 두 이미지를 벡터화 시킨 후, 두 벡터간의 유사도를 반환하는 네트워크입니다.
<img width="845" alt="샴" src="https://github.com/user-attachments/assets/ef6fe86e-9b18-422d-aeb0-bd297c3ad4cc">

* 모델 구조
  * 두 입력 이미지를 각각 처리하는 두 개의 동일한 신경망으로 구성됩니다.
  * 이미지를 입력으로 받으면 여러번 합성곱 연산을 거쳐 하나의 벡터 이미지로 인코딩합니다.
  * 이 때, 두 네트워크는 동일한 가중치를 공유합니다.
 
* 두 사진이 같은 경우 유사도를 1, 다른 경우 유사도를 0으로 주어 모델을 학습시켰습니다.
* 이를 통해 추출된 벡터 간 거리는 유사한 이미지끼리는 가까운 거리, 다른 이미지 간에는 먼 거리를 가집니다.

### 안면 인식 AI
> 전처리

안면 인식 AI의 전처리를 오픈소스인 Dlib와 face_recognition 라이브러리를 이용하여 진행합니다.<br>
이미지를 입력받으면 dlib의 cnn_face_detection을 사용하여 이미지 내에서 얼굴을 감지합니다.<br>
감지한 이미지는 face_recognition을 통해 얼굴 인코딩을 진행합니다.<br>
얼굴 인코딩은 얼굴 특징을 나타내는 128차원 벡터로 구성되며 이렇게 진행된 얼굴의 인코딩 정보를<br>
라벨링하여 저장하게 됩니다.<br>

> 인식

인식할 이미지를 입력받아 전처리를 통해 인코딩합니다. 두 얼굴의 인코딩 벡터 간의 유사도를 <br>
compare_face와 face_distance를 통해 유클리드 거리를 계산합니다.<br>
계산된 유클리드 거리의 값이 작을수록 두 인코딩 벡터가 유사하다는 것을 의미, 즉 두 얼굴이<br>
비슷하다는 것을 의미합니다. 계산된 거리가 설정한 임계값보다 작다면 같은 안면으로 인식<br>
크다면 다른 안면으로 인식합니다.


## 아키텍처
![Untitled (2)](https://github.com/user-attachments/assets/ae43da6d-f7b1-4f4e-9aab-81294999c450)


## 팀원 소개
### 곽미래
* 백엔드
* CI/CD

### 김수혁
* 비문 인식 AI
* 안면 인식 AI
  
### 이주혁
* 비문 탐지 AI
* AI 서버 구축
  
### 조은영
* 프론트엔드

### 최서현
* 백엔드
* 디자인
